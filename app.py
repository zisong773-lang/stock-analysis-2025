import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os
from datetime import datetime, timedelta
import textwrap

# --- åŸºç¡€åº“æ£€æŸ¥ ---
try:
    import yfinance as yf
    import numpy as np
except ImportError as e:
    st.error(f"ç¼ºå°‘å¿…è¦åº“ï¼Œè¯·å…ˆå®‰è£…: {e}")
    st.stop()

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="è‚¡ä»·å¤ç›˜ (æœ€ç»ˆä¿®å¤ç‰ˆ)", layout="wide")
st.title("ğŸ“ˆ 2025 è‚¡ä»·å¤ç›˜ç³»ç»Ÿï¼šæœ€ç»ˆä¿®å¤ç‰ˆ")
st.markdown("---")

# --- 0. ä»£ç†è®¾ç½® (ä¿®æ”¹ï¼šé»˜è®¤ä¸ºå…³é—­ï¼Œé€‚åº”äº‘ç«¯ç¯å¢ƒ) ---
st.sidebar.header("0. ç½‘ç»œä»£ç†è®¾ç½®")
# ã€å…³é”®ä¿®æ”¹ã€‘é»˜è®¤ value æ”¹ä¸º Falseï¼Œé˜²æ­¢äº‘ç«¯éƒ¨ç½²æ—¶æŠ¥é”™
enable_proxy = st.sidebar.checkbox("å¼€å¯ä»£ç†è¿æ¥ (æœ¬åœ°è¿è¡Œéœ€å‹¾é€‰)", value=False)
proxy_address = st.sidebar.text_input("ä»£ç†åœ°å€", value="http://127.0.0.1:17890")

if enable_proxy:
    os.environ["HTTP_PROXY"] = proxy_address
    os.environ["HTTPS_PROXY"] = proxy_address
    os.environ["NO_PROXY"] = "localhost,127.0.0.1"
else:
    os.environ.pop("HTTP_PROXY", None)
    os.environ.pop("HTTPS_PROXY", None)

# --- 1. æ•°æ®æ¥æº ---
st.sidebar.header("1. æ•°æ®æ¥æº")
data_source = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["Yahoo Finance (å®ç›˜æ•°æ®)", "Excelæ–‡ä»¶ (Pricesè¡¨)", "ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (æµ‹è¯•ç”¨)"])

# --- 2. ç»˜å›¾å‚æ•° ---
st.sidebar.header("2. ç»˜å›¾å‚æ•°")
default_start = pd.to_datetime("2024-12-23")
default_end = min(pd.to_datetime("2025-12-23"), datetime.today())

ticker = st.sidebar.text_input("è‚¡ç¥¨ä»£ç ", value="6324.T")
start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", value=default_start)
end_date_input = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", value=default_end, max_value=datetime.today())
end_date_final = end_date_input + timedelta(days=1)

# --- 3. è§†è§‰ä¸æ’ç‰ˆå¾®è°ƒ ---
st.sidebar.header("3. è§†è§‰ä¸æ’ç‰ˆå¾®è°ƒ")
st.sidebar.info("ğŸ’¡ æç¤ºï¼šå¦‚æœä¸‹è½½åå­—ä½“å¤ªå°ï¼Œè¯·è°ƒå¤§ã€å¯¼å‡ºå€ç‡ã€‘ä¸‹æ–¹çš„å­—ä½“æ»‘å—ï¼Œæˆ–å°†å€ç‡è®¾ä¸º 1xã€‚")

st.sidebar.subheader("ğŸ–¨ï¸ å¯¼å‡ºè®¾ç½® (å…³é”®)")
export_scale = st.sidebar.radio(
    "å¯¼å‡ºæ¸…æ™°åº¦/å€ç‡", 
    [1, 2, 3], 
    index=0, 
    format_func=lambda x: f"{x}å€ (1å€=æ‰€è§å³æ‰€å¾—, 3å€=å­—ä¼šå˜å°ä½†è¶…æ¸…)",
    horizontal=True
)

phase_font_size = st.sidebar.slider("é¡¶éƒ¨é˜¶æ®µå­—ä½“å¤§å°", 10, 80, 20)
event_font_size = st.sidebar.slider("ä¸‹æ–¹äº‹ä»¶å­—ä½“å¤§å°", 8, 60, 16)

phase_label_y = st.sidebar.slider("é˜¶æ®µæ ‡ç­¾åŸºç¡€é«˜åº¦", 1.0, 1.3, 1.02, 0.01)
phase_stagger = st.sidebar.checkbox("å¼€å¯é¡¶éƒ¨æ ‡ç­¾é”™è½", value=True)
phase_stagger_gap = st.sidebar.slider("é¡¶éƒ¨é”™è½é«˜åº¦å·®", 0.01, 0.15, 0.05)

label_wrap_width = st.sidebar.slider("æ ‡ç­¾æ¢è¡Œå­—æ•°", 5, 30, 10)
hover_wrap_width = st.sidebar.slider("æ‚¬æµ®æ–‡å­—æ¢è¡Œå­—æ•°", 20, 80, 40)

arrow_len_base = st.sidebar.slider("å¼•çº¿åŸºç¡€é•¿åº¦", 20, 150, 50)
stagger_steps = st.sidebar.slider("ä¸‹æ–¹é˜²é‡å é˜¶æ¢¯æ•°", 3, 10, 6)
stagger_gap = st.sidebar.slider("ä¸‹æ–¹é˜¶æ¢¯å‚ç›´é—´è·", 10, 100, 50)

y_headroom = st.sidebar.slider("é¡¶éƒ¨å¼ºåˆ¶ç•™ç™½ (%)", 0, 100, 7)
bg_opacity = st.sidebar.slider("æ ‡ç­¾èƒŒæ™¯é€æ˜åº¦", 0.1, 1.0, 0.8)
bottom_margin = st.sidebar.slider("åº•éƒ¨ç•™ç™½é«˜åº¦", 50, 150, 80)
top_margin = st.sidebar.slider("é¡¶éƒ¨ç•™ç™½é«˜åº¦", 100, 300, 150)

# --- 4. ä¸Šä¼ æ–‡ä»¶ ---
st.sidebar.header("4. ä¸Šä¼ æ–‡ä»¶")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼  Excel (ä¸­æ–‡ç‰ˆ)", type=["xlsx"])

# --- è¾…åŠ©å‡½æ•° ---
def process_text_smart(text, wrap_width):
    if not isinstance(text, str): return str(text)
    lines = text.split('\n')
    processed_lines = []
    for line in lines:
        line = line.strip()
        if not line: continue
        line = line.replace("<br>", "\n")
        sub_lines = line.split("\n")
        for sl in sub_lines:
            wrapped = textwrap.wrap(sl, width=wrap_width)
            processed_lines.extend(wrapped)
    return "<br>".join(processed_lines)

def generate_mock_data(start, end):
    dates = pd.date_range(start=start, end=end, freq='B')
    n = len(dates)
    if n == 0: return None
    np.random.seed(42)
    returns = np.random.normal(loc=0.0003, scale=0.015, size=n)
    price = 3000 * np.cumprod(1 + returns)
    df = pd.DataFrame(index=dates)
    df['Close'] = price
    df['Open'] = df['Close'].shift(1).fillna(price[0]) * (1 + np.random.randn(n)*0.005)
    return df.round(0)

def load_data_from_excel(file):
    try:
        df = pd.read_excel(file, sheet_name='Prices')
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        return df
    except: 
        return None

def get_stock_data(source, ticker, start, end, uploaded_file):
    if source == "Yahoo Finance (å®ç›˜æ•°æ®)":
        start_str = start.strftime('%Y-%m-%d')
        end_str = end.strftime('%Y-%m-%d')
        try:
            with st.spinner("æ­£åœ¨è¿æ¥ Yahoo..."):
                dat = yf.Ticker(ticker)
                df = dat.history(start=start_str, end=end_str, auto_adjust=True)
            if df.empty:
                st.error("âŒ Yahoo è¿”å›ç©ºæ•°æ®")
                return None
            if df.index.tz is not None: df.index = df.index.tz_localize(None)
            return df
        except Exception as e:
            st.error(f"è¿æ¥å¤±è´¥: {e}")
            return None
    elif source == "Excelæ–‡ä»¶ (Pricesè¡¨)":
        return load_data_from_excel(uploaded_file) if uploaded_file else None
    else:
        return generate_mock_data(start, end)

# --- æ™ºèƒ½è§£æä¸èšåˆå‡½æ•° ---
def find_col_in_list(columns, keywords, exclude_keywords=None):
    for col in columns:
        col_str = str(col)
        if exclude_keywords and any(ex in col_str for ex in exclude_keywords):
            continue
        for kw in keywords:
            if kw in col_str:
                return col
    return None

def extract_table_dynamically(df, required_keywords, name="Table"):
    def check_columns(cols):
        found_cols = {}
        for key, (kws, ex_kws) in required_keywords.items():
            found = find_col_in_list(cols, kws, ex_kws)
            if found:
                found_cols[key] = found
            else:
                return None
        return found_cols

    found_cols = check_columns(df.columns)
    if found_cols: return df, found_cols

    max_scan = min(len(df), 100)
    for i in range(max_scan):
        row_values = df.iloc[i].astype(str).tolist()
        is_header_row = True
        for key, (kws, ex_kws) in required_keywords.items():
            if not any(kw in cell for cell in row_values for kw in kws):
                is_header_row = False
                break
        
        if is_header_row:
            new_df = df.iloc[i+1:].copy()
            new_df.columns = df.iloc[i]
            new_found_cols = check_columns(new_df.columns)
            if new_found_cols:
                return new_df, new_found_cols
    return None, None

def aggregate_details(df, group_keys, detail_col, output_detail_name="Detail"):
    if not detail_col: return df
    for k in group_keys:
        df[k] = df[k].ffill()
    
    def join_text(series):
        texts = [str(s).strip() for s in series if pd.notna(s) and str(s).strip() != '']
        if not texts: return None
        if len(texts) == 1: return texts[0]
        return "<br>".join([f"â€¢ {t}" for t in texts])

    agg_dict = {detail_col: join_text}
    temp = df.groupby(group_keys, as_index=False).agg(agg_dict)
    temp = temp.rename(columns={detail_col: output_detail_name})
    return temp

def parse_uploaded_excel(file):
    try:
        all_sheets = pd.read_excel(file, sheet_name=None)
        events_list = []
        phases_list = []
        
        event_rules = {
            'event': (['ä¸»è¦é©±åŠ¨', 'Event'], None),
            'date': (['æ—¥æœŸ', 'Date', 'æ—¶é—´'], ['èµ·å§‹', 'å¼€å§‹', 'Start', 'ç»“æŸ', 'End'])
        }
        phase_rules = {
            'phase': (['é˜¶æ®µæ¦‚è¿°', 'Phase'], None),
            'start': (['èµ·å§‹æ—¥æœŸ', 'å¼€å§‹æ—¥æœŸ', 'Start'], None),
            'end': (['ç»“æŸæ—¥æœŸ', 'End'], None)
        }

        for sheet_name, df in all_sheets.items():
            df.columns = df.columns.astype(str).str.strip()
            
            # 1. æå–äº‹ä»¶
            e_df, e_cols = extract_table_dynamically(df, event_rules, "Events")
            if e_df is not None:
                hover_col = find_col_in_list(e_df.columns, ['è¯¦ç»†è§£é‡Š', 'å› æœé“¾', 'Detailed'])
                cols_to_keep = [e_cols['date'], e_cols['event']]
                if hover_col: cols_to_keep.append(hover_col)
                temp = e_df[cols_to_keep].copy()
                
                if hover_col:
                    temp = aggregate_details(temp, [e_cols['date'], e_cols['event']], hover_col, 'è¯¦ç»†è§£é‡Š')
                    temp = temp.rename(columns={e_cols['date']: 'Date', e_cols['event']: 'ä¸»è¦é©±åŠ¨'})
                else:
                    temp = temp.rename(columns={e_cols['date']: 'Date', e_cols['event']: 'ä¸»è¦é©±åŠ¨'})

                # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šä½¿ç”¨ errors='coerce' é¿å… "èµ·å§‹æ—¥æœŸ" æ–‡æœ¬æŠ¥é”™
                temp['Date'] = pd.to_datetime(temp['Date'], errors='coerce')
                temp = temp.dropna(subset=['Date'])
                if not temp.empty: events_list.append(temp)
            
            # 2. æå–é˜¶æ®µ
            p_df, p_cols = extract_table_dynamically(df, phase_rules, "Phases")
            if p_df is not None:
                hover_col = find_col_in_list(p_df.columns, ['å…³é”®å› ç´ ', 'è¦ç‚¹', 'Key Factors'])
                cols_to_keep = [p_cols['start'], p_cols['end'], p_cols['phase']]
                if hover_col: cols_to_keep.append(hover_col)
                temp = p_df[cols_to_keep].copy()
                
                if hover_col:
                    temp = aggregate_details(temp, [p_cols['start'], p_cols['end'], p_cols['phase']], hover_col, 'å…³é”®å› ç´ ')
                    temp = temp.rename(columns={p_cols['start']: 'Start date', p_cols['end']: 'End date', p_cols['phase']: 'é˜¶æ®µæ¦‚è¿°'})
                else:
                    temp = temp.rename(columns={p_cols['start']: 'Start date', p_cols['end']: 'End date', p_cols['phase']: 'é˜¶æ®µæ¦‚è¿°'})
                
                # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šä½¿ç”¨ errors='coerce'
                temp['Start date'] = pd.to_datetime(temp['Start date'], errors='coerce')
                temp['End date'] = pd.to_datetime(temp['End date'], errors='coerce')
                temp = temp.dropna(subset=['Start date'])
                if not temp.empty: phases_list.append(temp)

        events_df = pd.concat(events_list, ignore_index=True) if events_list else None
        phases_df = pd.concat(phases_list, ignore_index=True) if phases_list else None
        return events_df, phases_df

    except Exception as e:
        import traceback
        st.error(f"è§£æ Excel å‡ºé”™: {e}")
        st.text(traceback.format_exc())
        return None, None

# --- ä¸»ç¨‹åº ---
if uploaded_file:
    stock_df = get_stock_data(data_source, ticker, start_date, end_date_final, uploaded_file)
    
    if stock_df is not None and not stock_df.empty:
        events_df, phases_df = parse_uploaded_excel(uploaded_file)
        
        if events_df is None and phases_df is None:
            st.warning("âš ï¸ æœªèƒ½è¯†åˆ«å†…å®¹ã€‚è¯·ç¡®ä¿ExcelåŒ…å«ï¼š'ä¸»è¦é©±åŠ¨'æˆ–'é˜¶æ®µæ¦‚è¿°'åˆ—ã€‚")
        else:
            try:
                fig = go.Figure()

                # ç»˜åˆ¶è‚¡ä»·
                fig.add_trace(go.Scatter(
                    x=stock_df.index, y=stock_df['Close'],
                    mode='lines', name=f"{ticker} æ”¶ç›˜ä»·",
                    line=dict(color='#1976D2', width=2.5), line_shape='spline'
                ))
                data_start, data_end = stock_df.index.min(), stock_df.index.max()

                # ç»˜åˆ¶é˜¶æ®µ
                if phases_df is not None and not phases_df.empty:
                    phase_colors = ["rgba(255,99,132,0.12)", "rgba(54,162,235,0.12)", "rgba(255,206,86,0.15)", "rgba(75,192,192,0.12)"]
                    target_col = find_col_in_list(phases_df.columns, ['é˜¶æ®µæ¦‚è¿°'])
                    for i, row in phases_df.iterrows():
                        p_start = max(row['Start date'], data_start)
                        p_end = min(row['End date'], data_end)
                        if p_start < p_end:
                            mid_point = p_start + (p_end - p_start) / 2
                            fig.add_vrect(x0=p_start, x1=p_end, fillcolor=phase_colors[i % 4], layer="below", line_width=0)
                            
                            raw_text = str(row.get(target_col, ''))
                            wrapped_text = process_text_smart(raw_text, label_wrap_width)
                            
                            hover_col = find_col_in_list(phases_df.columns, ['å…³é”®å› ç´ ', 'è¦ç‚¹', 'Key Factors'])
                            hover_text_raw = str(row.get(hover_col, '')) if hover_col else raw_text
                            hover_text = process_text_smart(hover_text_raw, hover_wrap_width)
                            
                            current_phase_y = phase_label_y
                            if phase_stagger: current_phase_y += (i % 2) * phase_stagger_gap

                            fig.add_annotation(
                                x=mid_point, y=current_phase_y, yref="paper", 
                                text=f"<b>{wrapped_text}</b>", hovertext=hover_text,
                                showarrow=False, font=dict(size=phase_font_size, color="#555"), 
                                bgcolor="rgba(255,255,255,0.8)", borderpad=3
                            )

                # ç»˜åˆ¶äº‹ä»¶
                if events_df is not None and not events_df.empty:
                    events_df = events_df.sort_values('Date').reset_index(drop=True)
                    label_col = find_col_in_list(events_df.columns, ['ä¸»è¦é©±åŠ¨'])
                    for i, row in events_df.iterrows():
                        event_date = row['Date']
                        if data_start <= event_date <= data_end:
                            try:
                                idx = stock_df.index.get_indexer([event_date], method='nearest')[0]
                                curr = stock_df.index[idx]
                                vals = stock_df.loc[curr]
                                close_p = vals['Close'].iloc[0] if isinstance(vals['Close'], pd.Series) else vals['Close']
                                open_p = vals['Open'].iloc[0] if isinstance(vals['Open'], pd.Series) else vals['Open']
                                
                                y_anchor = close_p
                                is_rising = close_p >= open_p
                                ay_dir = 1 if is_rising else -1
                                color = "#D32F2F" if is_rising else "#00796B"
                                stagger_level = i % stagger_steps 
                                current_arrow_len = arrow_len_base + (stagger_level * stagger_gap)
                                
                                txt = str(row.get(label_col, ''))
                                formatted = process_text_smart(txt, label_wrap_width)
                                hover_col = find_col_in_list(events_df.columns, ['è¯¦ç»†è§£é‡Š', 'å› æœé“¾', 'Detailed'])
                                hover_text_raw = str(row.get(hover_col, '')) if hover_col else txt
                                hover_formatted = process_text_smart(hover_text_raw, hover_wrap_width)
                                
                                fig.add_annotation(
                                    x=curr, y=y_anchor, text=f"<b>{formatted}</b>",
                                    hovertext=hover_formatted, 
                                    showarrow=True, arrowhead=2, arrowwidth=1.5, arrowcolor=color,
                                    ax=0, ay=current_arrow_len * ay_dir,
                                    font=dict(size=event_font_size, color="#333"), 
                                    bgcolor=f"rgba(255,255,255,{bg_opacity})", 
                                    bordercolor=color, borderwidth=1, borderpad=3,
                                    hoverlabel=dict(bgcolor="white", font=dict(size=event_font_size))
                                )
                            except: pass

                # å¸ƒå±€
                y_max = stock_df['Close'].max()
                y_min = stock_df['Close'].min()
                range_max = y_max * (1 + y_headroom / 100)
                range_min = y_min * 0.95

                fig.update_layout(
                    title=dict(text=f"{ticker} æ”¶ç›˜ä»·è¶‹åŠ¿å¤ç›˜", x=0.5, font=dict(size=22)),
                    yaxis_title="æ”¶ç›˜ä»· (JPY)",
                    height=950, xaxis_rangeslider_visible=False,
                    template="plotly_white", margin=dict(t=top_margin, r=50, b=bottom_margin), 
                    plot_bgcolor='rgba(250,250,250,1)', hovermode="x unified", dragmode="pan"
                )
                fig.update_xaxes(tickformat="%yå¹´%-mæœˆ", dtick="M1", showgrid=True, gridcolor='rgba(0,0,0,0.05)')
                fig.update_yaxes(range=[range_min, range_max], showgrid=True, gridcolor='rgba(0,0,0,0.05)')

                st.plotly_chart(fig, use_container_width=True, config={
                    'editable': True, 'scrollZoom': True,
                    'toImageButtonOptions': {
                        'format': 'png', 'filename': f'{ticker}_å¤ç›˜åˆ†æ',
                        'height': 950 * export_scale, 'width': 1600 * export_scale, 'scale': 1 
                    }
                })

            except Exception as e:
                import traceback
                st.error(f"ç»˜å›¾æŠ¥é”™: {e}")
                st.text(traceback.format_exc())
    else:
        if data_source != "Yahoo Finance (å®ç›˜æ•°æ®)" and (stock_df is None or stock_df.empty):
             st.warning("âš ï¸ æ•°æ®ä¸ºç©º")
else:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼  Excel æ–‡ä»¶")
